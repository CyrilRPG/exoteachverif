# app.py (v3) ‚Äî robust I3/I4+ with auto data-start detection & clean errors CSV
import json
import re
from typing import List, Tuple, Dict, Any, Optional

import pandas as pd
import streamlit as st

st.set_page_config(page_title="V√©rif Groupes √âtudiants ‚Äî I3/I4+", page_icon="‚úÖ", layout="wide")
st.markdown("""
<style>
:root { --radius: 14px; }
.block-container { padding-top: 1rem; }
.stButton>button, .stDownloadButton>button { border-radius: var(--radius); padding:0.55rem 0.9rem; }
.kpi { border:1px solid #e5e7eb; border-radius: var(--radius); padding:0.8rem; background:#fafafa; }
small.dim { color:#6b7280; }
</style>
""", unsafe_allow_html=True)

st.title("V√©rification des groupes √©tudiants ‚Äî format I3/I4+")
st.caption("Rep√®re I3 comme libell√©, d√©tecte automatiquement la premi√®re ligne de donn√©es sous I3, et garantit des exports propres.")

# ---------- R√©f√©rentiel officiel ----------
OFFICIEL: Dict[int, Tuple[str, str]] = {
    5944: ("USPN", "Classe"), 5943: ("USPN", "Classe"), 5942: ("USPN", "Classe"),
    5018: ("USPN", "Fili√®re"), 5017: ("USPN", "Fili√®re"), 5016: ("USPN", "Fili√®re"),
    5935: ("PASS UPC", "Classe"), 5934: ("PASS UPC", "Classe"), 5933: ("PASS UPC", "Classe"), 5932: ("PASS UPC", "Classe"),
    5013: ("PASS UPC", "Fili√®re"), 5012: ("PASS UPC", "Fili√®re"),
    5940: ("PASS SU", "Classe"), 5939: ("PASS SU", "Classe"), 5938: ("PASS SU", "Classe"), 5937: ("PASS SU", "Classe"), 5936: ("PASS SU", "Classe"),
    5014: ("PASS SU", "Fili√®re"),
    5941: ("PASS UVSQ", "Classe"), 5015: ("PASS UVSQ", "Fili√®re"),
    5945: ("PASS UPS", "Classe"), 5019: ("PASS UPS", "Fili√®re"),
    5953: ("LSPS2 UPEC", "Classe"), 5952: ("LSPS2 UPEC", "Classe"), 5951: ("LSPS2 UPEC", "Classe"),
    5950: ("LSPS1 UPEC", "Classe"), 5949: ("LSPS1 UPEC", "Classe"), 5948: ("LSPS1 UPEC", "Classe"), 5947: ("LSPS1 UPEC", "Classe"),
    5946: ("LAS1 UPEC", "Classe"),
    5032: ("LSPS3 UPEC", "Fili√®re"), 5022: ("LSPS2 UPEC", "Fili√®re"), 5021: ("LSPS1 UPEC", "Fili√®re"), 5020: ("LAS1 UPEC", "Fili√®re"),
    6127: ("PAES Distanciel", "Classe"),
    6125: ("PAES Pr√©sentiel", "Classe"), 6124: ("PAES Pr√©sentiel", "Classe"), 6123: ("PAES Pr√©sentiel", "Classe"), 6122: ("PAES Pr√©sentiel", "Classe"),
    5024: ("PAES Distanciel", "Fili√®re"), 5023: ("PAES Pr√©sentiel", "Fili√®re"),
    6120: ("Terminale Sant√© Distanciel", "Classe"),
    6119: ("Terminale Sant√© Pr√©sentiel", "Classe"), 6118: ("Terminale Sant√© Pr√©sentiel", "Classe"), 6117: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6116: ("Terminale Sant√© Pr√©sentiel", "Classe"), 6115: ("Terminale Sant√© Pr√©sentiel", "Classe"), 6114: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6113: ("Terminale Sant√© Pr√©sentiel", "Classe"), 6112: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    5026: ("Terminale Sant√© Distanciel", "Fili√®re"), 5025: ("Terminale Sant√© Pr√©sentiel", "Fili√®re"),
    6128: ("Premi√®re √âlite", "Classe"), 5027: ("Premi√®re √âlite", "Fili√®re"),
}

NUM_RE = re.compile(r"\d+")

def parse_numeros(groupes_str: Any) -> List[int]:
    if pd.isna(groupes_str):
        return []
    s = str(groupes_str)
    return [int(m.group(0)) for m in NUM_RE.finditer(s)]

def analyser_groupes(groupes_str: Any) -> str:
    nums = parse_numeros(groupes_str)
    filieres = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1] == "Fili√®re"]
    classes  = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1] == "Classe"]

    if len(filieres) == 0 and len(classes) == 0:
        return "Pas de classe ni de fili√®re"
    if len(filieres) == 0 and len(classes) > 0:
        return "Pas de fili√®re"
    if len(classes) == 0 and len(filieres) > 0:
        return "Pas de classe"
    if len(filieres) > 1 and len(classes) > 1:
        return "Plusieurs fili√®res et plusieurs classes"
    if len(filieres) > 1:
        return "Plusieurs fili√®res"
    if len(classes) > 1:
        return "Plusieurs classes"

    filiere_nom = OFFICIEL[filieres[0]][0]
    classe_nom  = OFFICIEL[classes[0]][0]
    if filiere_nom != classe_nom:
        return "Classe et fili√®re incoh√©rents"
    return "OK"

def extra_info(groupes_str: Any) -> Dict[str, Any]:
    nums = parse_numeros(groupes_str)
    connus = [n for n in nums if n in OFFICIEL]
    inconnus = [n for n in nums if n not in OFFICIEL]
    filieres = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1]=="Fili√®re"]
    classes  = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1]=="Classe"]
    filiere_label = f"{OFFICIEL[filieres[0]][0]} ({filieres[0]})" if len(filieres)==1 else None
    classe_label = f"{OFFICIEL[classes[0]][0]} ({classes[0]})" if len(classes)==1 else None
    return {"NumerosTrouv√©s": nums, "NumerosConnus": connus, "NumerosInconnus": inconnus,
            "FiliereD√©duite": filiere_label, "ClasseD√©duite": classe_label}

def excel_col_to_index(col_letter: str) -> int:
    col_letter = col_letter.strip().upper()
    total = 0
    for ch in col_letter:
        if not ('A' <= ch <= 'Z'):
            raise ValueError("Lettre de colonne invalide.")
        total = total * 26 + (ord(ch) - ord('A') + 1)
    return total - 1

def make_unique(cols: List[str]) -> List[str]:
    seen: Dict[str, int] = {}
    out: List[str] = []
    for c in cols:
        c = str(c)
        if c in seen:
            seen[c] += 1
            out.append(f"{c}.{seen[c]}")
        else:
            seen[c] = 0
            out.append(c)
    return out

def autodetect_name_columns(columns: List[str]) -> Tuple[Optional[str], Optional[str]]:
    lower_map = {c: str(c).strip().lower() for c in columns}
    nom_candidates = [c for c, l in lower_map.items() if any(k in l for k in ["nom", "last name"])]
    prenom_candidates = [c for c, l in lower_map.items() if any(k in l for k in ["pr√©nom", "prenom", "first name"])]
    return (nom_candidates[0] if nom_candidates else None,
            prenom_candidates[0] if prenom_candidates else None)

def detect_data_start(raw: pd.DataFrame, groupes_col_idx: int, header_row_idx: int) -> int:
    """
    Cherche la premi√®re ligne non vide sous l'en-t√™te dans la colonne Groupes.
    Si rien n'est trouv√©, retourne header_row_idx+1 (ancienne logique).
    """
    start_probe = header_row_idx + 1
    max_probe = min(len(raw), header_row_idx + 50)  # on scanne 50 lignes max
    for r in range(start_probe, max_probe):
        val = raw.iat[r, groupes_col_idx] if groupes_col_idx < raw.shape[1] else None
        if pd.notna(val) and str(val).strip() != "":
            return r
    return start_probe

# ---------- Sidebar ----------
with st.sidebar:
    st.header("‚öôÔ∏è Import")
    use_sheet = st.text_input("Nom de l'onglet (laisser vide pour auto)", value="")
    col_letter_override = st.text_input("Colonne Groupes (d√©faut I)", value="I")
    start_row_manual = st.number_input("Forcer ligne de d√©part (0 = auto)", min_value=0, value=0, step=1)
    show_debug = st.checkbox("Afficher colonnes techniques", value=False)
    st.markdown("---")
    st.header("üß≠ Colonnes Nom/Pr√©nom")
    export_semicolon = st.checkbox("CSV erreurs avec point-virgule (;)", value=True)
    st.caption("Encodage UTF-8-SIG pour Excel FR.")

uploaded = st.file_uploader("D√©pose un fichier Excel (.xlsx, .xls)", type=["xlsx", "xls"])
if not uploaded:
    st.info("Charge un fichier pour commencer.")
    st.stop()

xl = pd.ExcelFile(uploaded)
sheet_name = use_sheet if (use_sheet and use_sheet in xl.sheet_names) else xl.sheet_names[0]

try:
    raw = pd.read_excel(uploaded, sheet_name=sheet_name, header=None)
except Exception as e:
    st.error(f"Erreur de lecture: {e}")
    st.stop()

st.write(f"**Onglet lu:** `{sheet_name}`")

# I3 / headers
header_row_idx = 2
try:
    groupes_col_idx = excel_col_to_index(col_letter_override or "I")
except Exception:
    groupes_col_idx = 8

if header_row_idx >= len(raw):
    st.error("La ligne d'en-t√™te (3) n'existe pas dans ce fichier.")
    st.stop()
if groupes_col_idx >= raw.shape[1]:
    st.error("La colonne Groupes d√©passe le nombre de colonnes du fichier.")
    st.stop()

# D√©termine la premi√®re ligne de donn√©es (auto ou forc√©e)
auto_start_row_idx = detect_data_start(raw, groupes_col_idx, header_row_idx)
start_row_idx = int(start_row_manual) - 1 if start_row_manual > 0 else auto_start_row_idx

headers = make_unique(list(raw.iloc[header_row_idx].astype(str)))
data = raw.iloc[start_row_idx:, :].reset_index(drop=True)
if data.shape[1] > len(headers):
    headers = headers + [f"COL_{i}" for i in range(data.shape[1] - len(headers))]
else:
    headers = headers[: data.shape[1]]
data.columns = headers

GROUPES_COL_NAME = "Groupes (d√©tect√© I3/auto)"
data[GROUPES_COL_NAME] = raw.iloc[start_row_idx:, groupes_col_idx].reset_index(drop=True)

# Sanity check: la colonne Groupes para√Æt-elle vide ?
digits4 = data[GROUPES_COL_NAME].astype(str).str.count(r"\d{4,}").sum()
if digits4 == 0:
    st.warning("‚ö†Ô∏è La colonne **Groupes** semble vide ou mal align√©e. "
               "V√©rifie l‚Äôonglet et/ou force la ligne de d√©part dans la barre lat√©rale.")
    st.write("Aper√ßu des 10 premi√®res valeurs de la colonne Groupes :")
    st.write(data[GROUPES_COL_NAME].head(10))

# Nom / Pr√©nom
nom_guess, prenom_guess = autodetect_name_columns(list(data.columns))
col1, col2 = st.columns(2)
with col1:
    nom_col = st.selectbox("Colonne Nom", options=["‚Äî"] + list(data.columns),
                           index=(["‚Äî"] + list(data.columns)).index(nom_guess) if nom_guess in (["‚Äî"] + list(data.columns)) else 0)
with col2:
    prenom_col = st.selectbox("Colonne Pr√©nom", options=["‚Äî"] + list(data.columns),
                              index=(["‚Äî"] + list(data.columns)).index(prenom_guess) if prenom_guess in (["‚Äî"] + list(data.columns)) else 0)
nom_col = None if nom_col == "‚Äî" else nom_col
prenom_col = None if prenom_col == "‚Äî" else prenom_col
if not nom_col or not prenom_col:
    st.warning("‚ö†Ô∏è Choisis/valide les colonnes **Nom** et **Pr√©nom** pour un export d'erreurs correct.")

# Analyse
df = data.copy()
df["Diagnostic"] = df[GROUPES_COL_NAME].apply(analyser_groupes)
extras = df[GROUPES_COL_NAME].apply(extra_info).apply(pd.Series)
df = pd.concat([df, extras], axis=1)

# R√©partition compl√®te
counts = df["Diagnostic"].value_counts().sort_index()
total = int(len(df))

c0, = st.columns(1)
with c0:
    st.markdown(f'<div class="kpi"><b>Total</b><br><span style="font-size:1.4rem">{total}</span></div>', unsafe_allow_html=True)

st.markdown("#### R√©partition par diagnostic")
rep_df = counts.reset_index()
rep_df.columns = ["Diagnostic", "Effectif"]
rep_df.loc[len(rep_df)] = ["Total", total]
st.dataframe(rep_df, use_container_width=True)

# Tableau principal
base_cols = [c for c in df.columns if c not in [GROUPES_COL_NAME, "Diagnostic", "FiliereD√©duite", "ClasseD√©duite", "NumerosTrouv√©s", "NumerosConnus", "NumerosInconnus"]]
display_cols = base_cols + [GROUPES_COL_NAME, "Diagnostic"]
if st.checkbox("Afficher colonnes techniques", value=show_debug):
    display_cols += ["FiliereD√©duite", "ClasseD√©duite", "NumerosTrouv√©s", "NumerosConnus", "NumerosInconnus"]
st.markdown("### Aper√ßu des donn√©es")
st.dataframe(df[display_cols], use_container_width=True)

# Export JSON
records = df.to_dict(orient="records")
json_bytes = json.dumps(records, ensure_ascii=False, indent=2).encode("utf-8")
st.download_button("‚¨áÔ∏è T√©l√©charger JSON (complet)", data=json_bytes, file_name="export_verifie.json", mime="application/json")

# Export erreurs (Nom, Pr√©nom, Diagnostic)
erreurs = df[df["Diagnostic"] != "OK"].copy()

def safe_col(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("").replace({"nan": ""})

if erreurs.empty:
    st.info("Aucune erreur √† exporter üéâ")
else:
    nom_for_export = nom_col if nom_col in erreurs.columns else None
    prenom_for_export = prenom_col if prenom_col in erreurs.columns else None
    if not nom_for_export:
        erreurs["__NOM__"] = ""
        nom_for_export = "__NOM__"
        st.warning("La colonne Nom s√©lectionn√©e n‚Äôexiste pas ‚Äî exportera une colonne vide.")
    if not prenom_for_export:
        erreurs["__PRENOM__"] = ""
        prenom_for_export = "__PRENOM__"
        st.warning("La colonne Pr√©nom s√©lectionn√©e n‚Äôexiste pas ‚Äî exportera une colonne vide.")
    export_df = pd.DataFrame({
        "Nom": safe_col(erreurs[nom_for_export]),
        "Pr√©nom": safe_col(erreurs[prenom_for_export]),
        "Diagnostic": safe_col(erreurs["Diagnostic"]),
    })
    sep = ";" if export_semicolon else ","
    csv_text = export_df.to_csv(index=False, sep=sep)
    csv_bytes = csv_text.encode("utf-8-sig")
    st.download_button("‚¨áÔ∏è T√©l√©charger uniquement les erreurs (CSV) ‚Äî 3 colonnes", data=csv_bytes,
                       file_name="erreurs_groupes.csv", mime="text/csv")

st.markdown("""
**Rappels :**  
- Auto-d√©tection de la premi√®re ligne de donn√©es sous I3 (tu peux aussi forcer une ligne de d√©part dans la sidebar).  
- Si la colonne Groupes para√Æt vide, l‚Äôapp te le signale avec un aper√ßu pour corriger facilement.  
- Export erreurs = **Nom, Pr√©nom, Diagnostic** (UTF-8-SIG, `;` activable).
""")
