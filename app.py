# app.py
import io
import json
import re
from typing import List, Tuple, Dict, Any, Optional

import pandas as pd
import streamlit as st

# -------------------------------
# CONFIG UI
# -------------------------------
st.set_page_config(page_title="V√©rif Groupes √âtudiants (I3/I4+)", page_icon="‚úÖ", layout="wide")
st.markdown("""
<style>
:root { --radius: 14px; }
.block-container { padding-top: 1rem; }
.stButton>button, .stDownloadButton>button { border-radius: var(--radius); padding:0.55rem 0.9rem; }
.kpi { border:1px solid #e5e7eb; border-radius: var(--radius); padding:0.8rem; background:#fafafa; }
small.dim { color:#6b7280; }
</style>
""", unsafe_allow_html=True)

st.title("V√©rification des groupes √©tudiants ‚Äî format I3/I4+")
st.caption("D√©tecte automatiquement la colonne Groupes √† partir de I3 (titre) et lit les donn√©es d√®s la ligne 4. Export d‚Äôerreurs = Nom, Pr√©nom, Diagnostic.")

# -------------------------------
# R√âF√âRENTIEL OFFICIEL
# num√©ro -> (nom fili√®re, 'Fili√®re'|'Classe')
# -------------------------------
OFFICIEL: Dict[int, Tuple[str, str]] = {
    5944: ("USPN", "Classe"),
    5943: ("USPN", "Classe"),
    5942: ("USPN", "Classe"),
    5018: ("USPN", "Fili√®re"),
    5017: ("USPN", "Fili√®re"),
    5016: ("USPN", "Fili√®re"),
    5935: ("PASS UPC", "Classe"),
    5934: ("PASS UPC", "Classe"),
    5933: ("PASS UPC", "Classe"),
    5932: ("PASS UPC", "Classe"),
    5013: ("PASS UPC", "Fili√®re"),
    5012: ("PASS UPC", "Fili√®re"),
    5940: ("PASS SU", "Classe"),
    5939: ("PASS SU", "Classe"),
    5938: ("PASS SU", "Classe"),
    5937: ("PASS SU", "Classe"),
    5936: ("PASS SU", "Classe"),
    5014: ("PASS SU", "Fili√®re"),
    5941: ("PASS UVSQ", "Classe"),
    5015: ("PASS UVSQ", "Fili√®re"),
    5945: ("PASS UPS", "Classe"),
    5019: ("PASS UPS", "Fili√®re"),
    5953: ("LSPS2 UPEC", "Classe"),
    5952: ("LSPS2 UPEC", "Classe"),
    5951: ("LSPS2 UPEC", "Classe"),
    5950: ("LSPS1 UPEC", "Classe"),
    5949: ("LSPS1 UPEC", "Classe"),
    5948: ("LSPS1 UPEC", "Classe"),
    5947: ("LSPS1 UPEC", "Classe"),
    5946: ("LAS1 UPEC", "Classe"),
    5032: ("LSPS3 UPEC", "Fili√®re"),
    5022: ("LSPS2 UPEC", "Fili√®re"),
    5021: ("LSPS1 UPEC", "Fili√®re"),
    5020: ("LAS1 UPEC", "Fili√®re"),
    6127: ("PAES Distanciel", "Classe"),
    6125: ("PAES Pr√©sentiel", "Classe"),
    6124: ("PAES Pr√©sentiel", "Classe"),
    6123: ("PAES Pr√©sentiel", "Classe"),
    6122: ("PAES Pr√©sentiel", "Classe"),
    5024: ("PAES Distanciel", "Fili√®re"),
    5023: ("PAES Pr√©sentiel", "Fili√®re"),
    6120: ("Terminale Sant√© Distanciel", "Classe"),
    6119: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6118: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6117: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6116: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6115: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6114: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6113: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    6112: ("Terminale Sant√© Pr√©sentiel", "Classe"),
    5026: ("Terminale Sant√© Distanciel", "Fili√®re"),
    5025: ("Terminale Sant√© Pr√©sentiel", "Fili√®re"),
    6128: ("Premi√®re √âlite", "Classe"),
    5027: ("Premi√®re √âlite", "Fili√®re"),
}

NUM_RE = re.compile(r"\d+")

# -------------------------------
# ANALYSE GROUPES
# -------------------------------
def parse_numeros(groupes_str: Any) -> List[int]:
    if pd.isna(groupes_str):
        return []
    return [int(m.group(0)) for m in NUM_RE.finditer(str(groupes_str))]

def analyser_groupes(groupes_str: Any) -> str:
    nums = parse_numeros(groupes_str)
    filieres = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1] == "Fili√®re"]
    classes  = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1] == "Classe"]

    if len(filieres) == 0 and len(classes) == 0:
        return "Pas de classe ni de fili√®re"
    if len(filieres) == 0 and len(classes) > 0:
        return "Pas de fili√®re"
    if len(classes) == 0 and len(filieres) > 0:
        return "Pas de classe"
    if len(filieres) > 1 and len(classes) > 1:
        return "Plusieurs fili√®res et plusieurs classes"
    if len(filieres) > 1:
        return "Plusieurs fili√®res"
    if len(classes) > 1:
        return "Plusieurs classes"

    filiere_nom = OFFICIEL[filieres[0]][0]
    classe_nom  = OFFICIEL[classes[0]][0]
    if filiere_nom != classe_nom:
        return "Classe et fili√®re incoh√©rents"
    return "OK"

def extra_info(groupes_str: Any) -> Dict[str, Any]:
    nums = parse_numeros(groupes_str)
    connus = [n for n in nums if n in OFFICIEL]
    inconnus = [n for n in nums if n not in OFFICIEL]
    filieres = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1]=="Fili√®re"]
    classes  = [n for n in nums if n in OFFICIEL and OFFICIEL[n][1]=="Classe"]
    filiere_label = None
    classe_label = None
    if len(filieres) == 1:
        filiere_label = f"{OFFICIEL[filieres[0]][0]} ({filieres[0]})"
    if len(classes) == 1:
        classe_label = f"{OFFICIEL[classes[0]][0]} ({classes[0]})"
    return {
        "NumerosTrouv√©s": nums,
        "NumerosConnus": connus,
        "NumerosInconnus": inconnus,
        "FiliereD√©duite": filiere_label,
        "ClasseD√©duite": classe_label,
    }

# -------------------------------
# UTILS IMPORT (I3/I4+)
# -------------------------------
def excel_col_to_index(col_letter: str) -> int:
    col_letter = col_letter.strip().upper()
    total = 0
    for ch in col_letter:
        if not ('A' <= ch <= 'Z'):
            raise ValueError("Lettre de colonne invalide.")
        total = total * 26 + (ord(ch) - ord('A') + 1)
    return total - 1

def make_unique(cols: List[str]) -> List[str]:
    seen: Dict[str, int] = {}
    out: List[str] = []
    for c in cols:
        c = str(c)
        if c in seen:
            seen[c] += 1
            out.append(f"{c}.{seen[c]}")
        else:
            seen[c] = 0
            out.append(c)
    return out

def autodetect_name_columns(columns: List[str]) -> Tuple[Optional[str], Optional[str]]:
    """Essaie de trouver Nom/Pr√©nom par mots-cl√©s."""
    lower_map = {c: str(c).strip().lower() for c in columns}
    nom_candidates = [c for c, l in lower_map.items() if any(k in l for k in ["nom", "last name"])]
    prenom_candidates = [c for c, l in lower_map.items() if any(k in l for k in ["pr√©nom", "prenom", "first name"])]
    nom_col = nom_candidates[0] if nom_candidates else None
    prenom_col = prenom_candidates[0] if prenom_candidates else None
    return nom_col, prenom_col

# -------------------------------
# SIDEBAR ‚Äî OPTIONS
# -------------------------------
with st.sidebar:
    st.header("‚öôÔ∏è Options d'import")
    use_sheet = st.text_input("Nom de l'onglet (laisser vide pour auto)", value="")
    col_letter_override = st.text_input("Colonne Groupes (d√©faut I)", value="I")
    start_row_override = st.number_input("Ligne de d√©part des donn√©es (d√©faut 4)", min_value=1, value=4, step=1)
    show_debug = st.checkbox("Afficher colonnes techniques", value=False)
    st.markdown("---")
    st.header("üß≠ Colonnes Nom/Pr√©nom")
    st.caption("Auto-d√©tection par mots-cl√©s. Tu peux forcer ci-dessous si besoin.")

# -------------------------------
# UPLOAD
# -------------------------------
uploaded = st.file_uploader("D√©pose un fichier Excel (.xlsx, .xls)", type=["xlsx", "xls"])
if not uploaded:
    st.info("Charge un fichier pour commencer.")
    st.stop()

# -------------------------------
# LECTURE BRUTE (sans header)
# -------------------------------
xl = pd.ExcelFile(uploaded)
sheet_name: Optional[str] = None
if use_sheet and use_sheet in xl.sheet_names:
    sheet_name = use_sheet
else:
    sheet_name = xl.sheet_names[0]

try:
    raw = pd.read_excel(uploaded, sheet_name=sheet_name, header=None)
except Exception as e:
    st.error(f"Erreur de lecture: {e}")
    st.stop()

st.write(f"**Onglet lu:** `{sheet_name}`")

# -------------------------------
# D√âTECTION I3 / EXTRACTION COL I
# -------------------------------
try:
    groupes_col_idx = excel_col_to_index(col_letter_override or "I")
except Exception:
    groupes_col_idx = 8  # fallback I

start_row_idx = int(start_row_override) - 1  # 0-based
header_row_idx = 2  # I3 (ligne 3) = en-t√™tes

if header_row_idx >= len(raw):
    st.error("La ligne d'en-t√™te (3) n'existe pas dans ce fichier.")
    st.stop()
if start_row_idx >= len(raw):
    st.error("La ligne de d√©part des donn√©es d√©passe la taille du fichier.")
    st.stop()
if groupes_col_idx >= raw.shape[1]:
    st.error("La colonne Groupes d√©passe le nombre de colonnes du fichier.")
    st.stop()

headers = make_unique(list(raw.iloc[header_row_idx].astype(str)))
data = raw.iloc[start_row_idx:, :].reset_index(drop=True)
# Harmonise le nombre de colonnes vs headers
if data.shape[1] > len(headers):
    headers = headers + [f"COL_{i}" for i in range(data.shape[1] - len(headers))]
else:
    headers = headers[: data.shape[1]]
data.columns = headers

GROUPES_COL_NAME = "Groupes (d√©tect√© I3/I4+)"
data[GROUPES_COL_NAME] = raw.iloc[start_row_idx:, groupes_col_idx].reset_index(drop=True)

# -------------------------------
# AUTO-DET NOM/PR√âNOM + UI DE FORCAGE
# -------------------------------
nom_guess, prenom_guess = autodetect_name_columns(list(data.columns))
col1, col2 = st.columns(2)
with col1:
    nom_col = st.selectbox("Colonne Nom", options=["‚Äî"] + list(data.columns),
                           index=(["‚Äî"] + list(data.columns)).index(nom_guess) if nom_guess in (["‚Äî"] + list(data.columns)) else 0)
with col2:
    prenom_col = st.selectbox("Colonne Pr√©nom", options=["‚Äî"] + list(data.columns),
                              index=(["‚Äî"] + list(data.columns)).index(prenom_guess) if prenom_guess in (["‚Äî"] + list(data.columns)) else 0)

nom_col = None if nom_col == "‚Äî" else nom_col
prenom_col = None if prenom_col == "‚Äî" else prenom_col

if not nom_col or not prenom_col:
    st.warning("‚ö†Ô∏è Merci de v√©rifier/choisir les colonnes **Nom** et **Pr√©nom** avant d‚Äôexporter les erreurs.")

# -------------------------------
# ANALYSE
# -------------------------------
df = data.copy()
df["Diagnostic"] = df[GROUPES_COL_NAME].apply(analyser_groupes)
extras = df[GROUPES_COL_NAME].apply(extra_info).apply(pd.Series)
df = pd.concat([df, extras], axis=1)

# -------------------------------
# KPIs
# -------------------------------
c1, c2, c3, c4, c5 = st.columns(5)
total = len(df)
n_ok = (df["Diagnostic"] == "OK").sum()
n_incoh = (df["Diagnostic"] == "Classe et fili√®re incoh√©rents").sum()
n_pas_fil = (df["Diagnostic"] == "Pas de fili√®re").sum()
n_pas_cls = (df["Diagnostic"] == "Pas de classe").sum()

with c1: st.markdown(f'<div class="kpi"><b>Total</b><br><span style="font-size:1.4rem">{total}</span></div>', unsafe_allow_html=True)
with c2: st.markdown(f'<div class="kpi"><b>OK</b><br><span style="font-size:1.4rem">{n_ok}</span></div>', unsafe_allow_html=True)
with c3: st.markdown(f'<div class="kpi"><b>Incoh√©rents</b><br><span style="font-size:1.4rem">{n_incoh}</span></div>', unsafe_allow_html=True)
with c4: st.markdown(f'<div class="kpi"><b>Pas de fili√®re</b><br><span style="font-size:1.4rem">{n_pas_fil}</span></div>', unsafe_allow_html=True)
with c5: st.markdown(f'<div class="kpi"><b>Pas de classe</b><br><span style="font-size:1.4rem">{n_pas_cls}</span></div>', unsafe_allow_html=True)

# -------------------------------
# TABLEAU
# -------------------------------
base_cols = [c for c in df.columns if c not in [GROUPES_COL_NAME, "Diagnostic", "FiliereD√©duite", "ClasseD√©duite", "NumerosTrouv√©s", "NumerosConnus", "NumerosInconnus"]]
display_cols = base_cols + [GROUPES_COL_NAME, "Diagnostic"]
if show_debug:
    display_cols += ["FiliereD√©duite", "ClasseD√©duite", "NumerosTrouv√©s", "NumerosConnus", "NumerosInconnus"]

st.markdown("### Aper√ßu des donn√©es")
st.dataframe(df[display_cols], use_container_width=True)

# -------------------------------
# EXPORTS
# -------------------------------
# JSON complet
records = df.to_dict(orient="records")
json_bytes = json.dumps(records, ensure_ascii=False, indent=2).encode("utf-8")
st.download_button("‚¨áÔ∏è T√©l√©charger JSON (complet)", data=json_bytes, file_name="export_verifie.json", mime="application/json")

# CSV erreurs (seulement Nom, Pr√©nom, Diagnostic)
erreurs = df[df["Diagnostic"] != "OK"].copy()

# Pr√©pare les 3 colonnes proprement
def safe_col(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("").replace({"nan": ""})

if erreurs.empty:
    st.info("Aucune erreur √† exporter üéâ")
else:
    # Cr√©e d'√©ventuelles colonnes vides si non s√©lectionn√©es
    if nom_col not in erreurs.columns:
        erreurs["__NOM__"] = ""
        nom_for_export = "__NOM__"
        st.warning("La colonne Nom s√©lectionn√©e n‚Äôexiste pas dans les donn√©es ‚Äî exportera une colonne vide.")
    else:
        nom_for_export = nom_col

    if prenom_col not in erreurs.columns:
        erreurs["__PRENOM__"] = ""
        prenom_for_export = "__PRENOM__"
        st.warning("La colonne Pr√©nom s√©lectionn√©e n‚Äôexiste pas dans les donn√©es ‚Äî exportera une colonne vide.")
    else:
        prenom_for_export = prenom_col

    export_df = pd.DataFrame({
        "Nom": safe_col(erreurs[nom_for_export]) if nom_for_export in erreurs else "",
        "Pr√©nom": safe_col(erreurs[prenom_for_export]) if prenom_for_export in erreurs else "",
        "Diagnostic": safe_col(erreurs["Diagnostic"]),
    })

    csv_err = export_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        "‚¨áÔ∏è T√©l√©charger uniquement les erreurs (CSV)",
        data=csv_err,
        file_name="erreurs_groupes.csv",
        mime="text/csv",
    )

st.markdown("""
#### Hypoth√®ses & r√®gles sp√©cifiques
- La cellule **I3** contient le libell√© ‚ÄúGroupes (chiffes s√©par√©s par un espace) Par exemple : 1 4 24‚Äù.
- Les **donn√©es** commencent √† **I4** (ligne 4).
- L‚Äôapp lit la **colonne I** comme colonne Groupes par d√©faut (for√ßable dans la barre lat√©rale).
- **Export erreurs CSV** : uniquement **Nom**, **Pr√©nom**, **Diagnostic**.
- Les num√©ros **non** pr√©sents dans la liste officielle **n‚Äôentra√Ænent pas d‚Äôerreur**.
""")
